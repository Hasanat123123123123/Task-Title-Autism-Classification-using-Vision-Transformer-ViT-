# -*- coding: utf-8 -*-
"""HomeTask_9B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12AceDrH9RILlFLqSP2OlhZp8EpPIbZfW
"""

!pip install pytorch-lightning transformers torchmetrics torchvision

# prompt: upload the folder from drive

!pip install pytorch-lightning transformers torchmetrics torchvision

from google.colab import drive
drive.mount('/content/drive')

# Assuming your folder is named 'my_folder' and is in your Google Drive's 'My Drive' folder
# Replace 'my_folder' with the actual name of your folder
!cp -r /content/drive/My\ Drive/my_folder /content/

import os
from pathlib import Path
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import pytorch_lightning as pl
from torch import nn
from transformers import ViTForImageClassification, ViTImageProcessor
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger
from torchmetrics.classification import Accuracy
import wandb

# Initialize W&B
wandb.init(project="autism-classifier")

# Set up the dataset paths
dataset_dir = "/content/drive/MyDrive/Colab Notebooks/datasets/Task9dataset"
train_dir = os.path.join(dataset_dir, "train")
val_dir = os.path.join(dataset_dir, "valid")
test_dir = os.path.join(dataset_dir, "test")

# Define transforms
image_processor = ViTImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k")
transform_train = transforms.Compose([
    transforms.RandomResizedCrop((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std),
])

transform_val_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std),
])

# Load datasets
train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)
val_dataset = datasets.ImageFolder(root=val_dir, transform=transform_val_test)
test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_val_test)

# Create dataloaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)

# Define the model
class AutismClassifier(pl.LightningModule):
    def __init__(self, num_classes=2, learning_rate=2e-5):
        super(AutismClassifier, self).__init__()
        self.model = ViTForImageClassification.from_pretrained(
            "google/vit-base-patch16-224-in21k",
            num_labels=num_classes,
        )
        self.learning_rate = learning_rate
        self.weight_decay = 1e-4
        self.train_accuracy = Accuracy(task="binary")
        self.val_accuracy = Accuracy(task="binary")
        self.test_accuracy = Accuracy(task="binary")

    def forward(self, pixel_values, labels=None):
        return self.model(pixel_values=pixel_values, labels=labels)

    def training_step(self, batch, batch_idx):
        inputs, labels = batch
        outputs = self(pixel_values=inputs, labels=labels)
        loss = outputs.loss
        logits = outputs.logits
        preds = torch.argmax(logits, dim=1)
        acc = self.train_accuracy(preds, labels)
        self.log("train_loss", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)
        self.log("train_acc", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)
        return loss

    def validation_step(self, batch, batch_idx):
        inputs, labels = batch
        outputs = self(pixel_values=inputs, labels=labels)
        loss = outputs.loss
        logits = outputs.logits
        preds = torch.argmax(logits, dim=1)
        acc = self.val_accuracy(preds, labels)
        self.log("val_loss", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)
        self.log("val_acc", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)

    def test_step(self, batch, batch_idx):
        inputs, labels = batch
        outputs = self(pixel_values=inputs, labels=labels)
        loss = outputs.loss
        logits = outputs.logits
        preds = torch.argmax(logits, dim=1)
        acc = self.test_accuracy(preds, labels)
        self.log("test_loss", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)
        self.log("test_acc", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)
        return [optimizer], [scheduler]

# Callbacks and Logger
checkpoint_callback = ModelCheckpoint(
    monitor="val_acc",
    dirpath="./checkpoints",
    filename="autism-classifier-{epoch:02d}-{val_acc:.2f}",
    save_top_k=1,
    mode="max",
)
lr_monitor = LearningRateMonitor(logging_interval="step")
logger = TensorBoardLogger("tb_logs", name="autism_classifier")

# Initialize the model
model = AutismClassifier(num_classes=2)

# Trainer
trainer = pl.Trainer(
    max_epochs=10,
    accelerator="gpu",
    devices=1,
    callbacks=[checkpoint_callback, lr_monitor],
    logger=logger,
    log_every_n_steps=10,
)

# Train the model
trainer.fit(model, train_loader, val_loader)

# Test the model
trainer.test(model, test_loader)

# Finish W&B run
wandb.finish()